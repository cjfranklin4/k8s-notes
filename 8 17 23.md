# Troubleshooting vhallenge
https://github.com/csfeeser/k8s/blob/master/troubleshooting_part1.md
- get events
```
kubectl get events
```
Recommended commands:
- `kubectl get`
- `kubectl describe`
- `kubectl edit`

# CKAD Exercises
https://github.com/dgkanatsios/CKAD-exercises/tree/main

# setting defaults for namespaces (for all containers)
- if no request/limit is specified, let there be a default
### LimitRange
- allows us to set default values and individual settings
- A **LimitRange** is a Kubernetes object that will allow an administrator to configure the maximum, minimum, and default values that a particular container or pod can have inside of a namespace. It uses the **LimitRanger** controller in order to add the default values in (_mutate_) or to verify that the values provided fall within the minimum and maximum ranges (_validate_).
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default: #Default Limit
      memory: 512Mi
    defaultRequest: #Default Request
      memory: 256Mi
    max: #Max amount of resources you can request
      memory: 1Gi
    min: #Min amount of resources you can request
      memory: 100Mi
    type: Container
```
![[Pasted image 20230817104057.png]]

- showing a LimitRange, a Pod Manifest, and a `kubectl describe ns`
![[Pasted image 20230817104748.png]]

# Admission Controller
![[Pasted image 20230817105335.png]]
![[Pasted image 20230817105423.png]]
- **Admission Controller** - A piece of code that intercepts requests on their way to the Kubernetes API server after the request is authenticated and authorized. They may either be **mutating** (altering the objects) or **validating** to allow limitations on requests to create, delete, modify or proxy to objects.

![[Pasted image 20230817105346.png]]
![[Pasted image 20230817105351.png]]
![[Pasted image 20230817105356.png]]

![[Pasted image 20230817105401.png]]
![[Pasted image 20230817105407.png]]

# Lab 39 - CReate a LimitRange admission conroller
- A **LimitRange** is a Kubernetes object that will allow an administrator to configure the maximum, minimum, and default values that a particular container or pod can have inside of a namespace. It uses the **LimitRanger** controller in order to add the default values in (_mutate_) or to verify that the values provided fall within the minimum and maximum ranges (_validate_).

- First, let's create a Pod that does not use a LimitRange
```
kubectl run no-lr --image=nginx:1.19.6
```

- then inspect to pod to see if nay requests
```
kubectl get pod no-lr -o yaml | grep request -A 5
```

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default:
      memory: 512Mi
    defaultRequest:
      memory: 256Mi
    max:
      memory: 1Gi
    min:
      memory: 100Mi
    type: Container
```
- initiate the limit range
```
kubectl apply -f ~/mycode/yaml/lim-ran.yml
```

- Congratulations! We have successfully used the LimitRanger Admission Controller via a Mutating Webhook to change the information added to etcd about this Pod. Specifically, we have used it to add the default amount of requests to be 256Mi to our container.

# Role based access control

![[Pasted image 20230817111840.png]]

![[Pasted image 20230817111845.png]]

![[Pasted image 20230817111850.png]]

![[Pasted image 20230817111855.png]]

# Lab 32 - Service Accounts
- check service accountd
```
kubectl get sa
```

- describe the service account
	- As you can see, there is nothing remarkable about this service account. This service account has no privileges, tokens, or anything of note. This is a safe service account to use, as it grants a Pod no privileges whatsoever.
```
kubectl describe sa default
```
```
Name:                default
Namespace:           default
Labels:              <none>
Annotations:         <none>
Image pull secrets:  <none>
Mountable secrets:   <none>
Tokens:              <none>
Events:              <none>

```

- Now, what if we want a container image to have the ability to make specific calls against the Kubernetes API Server? We'll need to create and configure it. Let's get started by creating a basic Service Account.
```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: privileged-sa
```

- In order to assign privileges and access to the Service Account, we'll need to create a Role and Rolebinding for the Service Account. For your purposeses, it is also possible to create ClusterRoles and ClusterRoleBindings for your Service Accounts.
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: privileged-sa-r
rules:
- apiGroups: ["", "apps"]
  resources: ["pods", "replicasets", "deployments"]
  verbs: ["get", "watch", "list", "create", "apply", "edit"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: privileged-sa-rb
subjects:
- kind: ServiceAccount
  name: privileged-sa
  namespace: default
roleRef:
  kind: Role
  name: privileged-sa-r
  apiGroup: rbac.authorization.k8s.io
```
- Create the Role and RoleBinding to grant our new Service Account access.
```
kubectl apply -f privileged-r-rb.yaml
```

- Verify the Role has been bound to the Service Account.
	- **Describing the Role Binding enables us to see what role and subjects have been bound together.** Here we can plainly see that the Service Account, _privileged-sa_ has been bound to the Role _privileged-sa_.
```
kubectl describe rolebinding privileged-sa-rb
```
```
Name:         privileged-sa-rb
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  Role
  Name:  privileged-sa
Subjects:
  Kind            Name           Namespace
  ----            ----           ---------
  ServiceAccount  privileged-sa  default
```

- Now that we have a privileged Service Account, let's put it to work by attaching it to a Pod we need to have the expanded privileges. We'll begin by creating the Pod Manifest.
```
apiVersion: v1
kind: Pod
metadata:
  name: privileged-pod
spec:
  serviceAccountName: privileged-sa
  containers:
  - name: privileged-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

- Verify the Service Account was added to the Pod:
```
kubectl describe pod privileged-pod | grep 'Service Account'
```

# Contexts

```
kubectl config view
```

- kubeconfig file
	- teaches the kubectl app on your personal compoyter how to talk to a kubernetes cluster
- set up kubectl
	- talk to any number of clusters
	- talk to any given user
	- on any given namespace
- .
# Lab 34
**What is the difference between a namespace and a context?**  
_A namespace is a logical division of a cluster. It may be limited by its own unique set of resource or network restraints. Common namespaces include "test", "dev", and "prod". A context is a reference to a specific cluster and namespace. Once created, a context may then be selected, which will default all the users' commands into the cluster and namespace associated with the context._

**How many contexts should you have in your Kubernetes cluster?**  
_To prevent accidentally issuing commands within wrong clusters or namespaces, a context should be created for each cluster and namespace therein._

- switch to a new context
```
kubectl config use-context kubernetes-the-alta3-way
```

- Contexts are stored in file, **~/.kube/config**. Editing this file is discouraged, and instead, we are encouraged to view and edit this file with the help of the kubectl client. Ask the kubectl client to reveal the contents of **~/.kube/config**:
```
kubectl config view
```
```yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://127.0.0.1:6443
  name: kubernetes-the-alta3-way
contexts:
- context:
   cluster: kubernetes-the-alta3-way
   user: admin
  name: kubernetes-the-alta3-way
current-context: kubernetes-the-alta3-way
kind: Config
preferences: {}
users:
- name: admin
  user:
    client-certificate: /home/student/k8s-certs/admin.pem
    client-key: /home/student/k8s-certs/admin-key.pem
```
- With this command, we're reading in the contents of the **kubeconfig** file. Its output is written in YAML, but this isn't a manifest or anything we'd want to send to the API Server. 
- Instead, it stores information concerning our **CLUSTERS**, **CONTEXTS**, and **USERS**. This is also the file that configures a context, which consists of the following three parameters: **Cluster**, **Namespace**, **User**. 
- It's how we define what **CLUSTER** we want to talk to, the **CREDENTIALS** we want to pass to the cluster, and what **Namespace** we want to control by default.

- As we observed from the **kubeconfig** file, we defined our **USER** with a **client-certificate** and a **client-key**. Let's check out the directory those keys are stored in.
```
cd ~/k8s-certs/

ls -l admin.*
```

- Editing the **kubeconfig** file is just as easy as viewing it using the command: **config set-context**. Think of the **config set-context** command like a command to program your universal remote control. The following command will create a new context named, **dev-context**, and associate it with the **dev** namespace.
```
kubectl config set-context dev-context --namespace=dev
```

- Use the _config_ use-context command to "source" the context to **dev-context**. This will make kubectl **ACTUALLY** switch over to the new context.
```
kubectl config use-context dev-context
```

- Show that the current context has updated to **dev-context**. You can view only the current-context by using the **--minify** flag.
	- The output shows the **dev-context** is lacking definition. The missing values include, **clusters**, **contexts[0].context.cluster**, **users**, and **contexts[0].context.user**. In short, we're missing a username (who) and cluster (where) definitions.
```
kubectl config view --minify
```
```yaml
apiVersion: v1
clusters: null
contexts:
- context:
    cluster: ""
    namespace: dev
    user: ""
  name: dev-context
current-context: dev-context
kind: Config
preferences: {}
users: null

```

- We can easily fill in these definitions with the flags **--cluster** and **--user**. The following command will complete "programming our universal remote control."
```
kubectl config set-context dev-context --namespace=dev --user=admin --cluster=kubernetes-the-alta3-way
```

```yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://127.0.0.1:6443
  name: kubernetes-the-alta3-way
contexts:
- context:
    cluster: kubernetes-the-alta3-way
    namespace: dev
    user: admin
  name: dev-context
- context:
    cluster: kubernetes-the-alta3-way
    user: admin
  name: kubernetes-the-alta3-way
current-context: dev-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    client-certificate: /home/student/k8s-certs/admin.pem
    client-key: /home/student/k8s-certs/admin-key.pem  

```

- List the current contexts that are available with **config get-contexts**.
```
kubectl config get-contexts
```

- Notice that the **kubernetes-the-alta3-way** context does not have an associated namespace. Remember, we can set (or update) a context's namespace with the **config set-context** command. Let's try setting the **kubernetes-the-alta3-way** context to **default**, rather than leaving it blank.
```
kubectl config set-context kubernetes-the-alta3-way --namespace=default
```

# Lab - Kubectl logs
This lab takes a look at some of the more advanced techniques of logging with and for Kubernetes. This includes basic logging with pods and containers, using a sidecar pod with Fluentd, as well as centralized logging with best practice of separation from the cluster.

- logs are made via CONTAINER. If a pod has multiple containers, you need to specify which container you want the logs from or it will default to the first container in the pod

### if you delete a pod/container, you also delete any logs as well

- In this example, we take a look at a pod specification that has two containers writing text to standard out.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox:1.34.0
    args: [/bin/sh, -c,
            'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']
  - name: countby3
    image: busybox:1.34.0
    args: [/bin/sh, -c,
            'i=0; while true; do echo "$(date): $i"; i=$((i+1)); sleep 3; done']
```

- While simple on the outside, Kubernetes inherent logging can show you a great deal more than just that. Below is a list of flags for the kubectl logs command. We will utilize some of these going forward.
![[Pasted image 20230817140147.png]]


- Let's check what the output is in the logs. Run the following command to try to look at the logs of the Pod we just created.
```
kubectl logs counter
```

- When you have a Pod with more than one container inside of it, you **can** specify which container you wish to view the logs of. Let's try that again with our **count** container.
```
kubectl logs counter -c count
```

- Now, let's try to follow the logs of the **count** container.
```
kubectl logs counter -c count -f
```

- Now let's try to get the logs from all of our containers in this Pod
	- Wait, this looks like we just got the logs from the **countby3** container! **That is because the logs are read from the first container first, and the second container second, not mixed together.** If you look back through the history of the output or use a tool like **less**, you can view all of them.
```
kubectl logs counter --all-containers
```

- Another way to look at some of the logs from all of our containers is to specify a **since** flag. Let's see what has happened in both of our containers for the last 10 seconds.
```
kubectl logs counter --all-containers --since 10s
```

- Or if we want to just look at the last 5 lines of logs for all of our containers, we can use the **tail** flag.
```
kubectl logs counter --all-containers --tail 5
```

- Although our logs already have timestamps on them, let's also see how the kubectl logs flag of **timestamps** is able to apply their own.
```
kubectl logs counter --all-containers --tail 5 --timestamps
```

# FluentD and RsysLog
- you want a fluentd logging agent on every single node
- fluentd can insert containers inside of the pod that collects information from the container it is sharing a pod with

![[Pasted image 20230817142024.png]]
![[Pasted image 20230817142029.png]]
![[Pasted image 20230817142033.png]]


# ConfigMaps and Volume Mounting
- we mount the configmap as a volume onto the container

![[Pasted image 20230817144656.png]]
![[Pasted image 20230817144700.png]]
![[Pasted image 20230817144705.png]]
![[Pasted image 20230817144710.png]]

- configMap examplw
![[Pasted image 20230817151931.png]]

- if you try to mount on top of an existing directory, the container will fail, as it will overwrite what is already there
- `subPath` - points to the actual configMap file
- `mountPath` - is what the container see
![[Pasted image 20230817155100.png]]

# Lab 39 - Persistent Configuration with ConfigMaps
- ConfigMaps allow Kubernetes Administrators to use more generic containers and pass specific configurations into them at the time of Pod creation.

- The first step with configmaps is to get organized. They get complicated very quickly, and versions spiral out of control. Let's do all our planning up front. We know we need to create three ConfigMaps. So we need a table to show the source and the object code.
![[Pasted image 20230817155352.png]]

- nginx-base.conf
```yaml
user  nginx;          #You are not ready for lines 1 -16, skip to line 17 where it gets interesting
worker_processes  1;       
error_log  /var/log/nginx/error.log warn;     
pid        /var/run/nginx.pid;       
events {
    worker_connections  1024;  
}    
http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log  /var/log/nginx/access.log  main;  
    sendfile        on;
    keepalive_timeout  65;
    server {                    # This tells NGINX to be an HTTP server or reverse proxy
        server_name  localhost; # This tells NGINX to serve requests on the localhost IP address
        listen 80;              # This tells NGINX to listen on (TCP) port 80
        root /var/www;          # This tells NGINX to establish the HTTP root at /var/www

        location / {            # If the path is just a slash, then do the following
        sendfile  on;           # This tells NGINX to send files if path matches slash (/).
         index index.html;      # and this is the file that NGINX will send if the HTTP request matches this path (/)
        }                       # The end of the (/) path directive

        location /static {      # NGINX performs the following tasks if the HTTP request matches this path (/static).
        autoindex on;           # This tells NGINX to add autoindex, a feature that shows files almost like an "FTP GUI".
        }                       # The end of the (/) path directive

    }                           # The end of the server block
}                               # The end of the http block
```

- We need to convert this file to a ConfigMap object. Here is the command to do that.
```
kubectl create configmap nginx-base-conf --from-file=nginx.conf=mycode/config/nginx-base.conf
```
- The command you just completed above needs more attention. If you do not insert the KEY, then the file will assume the name of the source file, which would NEVER work. Many people have lost hours on this one! Always assign the key, which is simply the destination filename.
```
 --from-file=nginx.conf=mycode/config/nginx-base.conf
             ----------
                 ^
                 |
      Really? We need this KEY???  
```

- Now let's retrieve the yaml for that configmap with the following command.
```
kubectl get configmaps nginx-base-conf -o yaml
```

- Clearly a configmap is no longer something that we want to edit directly. So we will follow a convention just to stay organized!
> 1. The source file will be stored in mycode/config/nginx-base-conf.conf
> 2. The yaml file will be stored in mycode/yaml/nginx-base-conf.yaml
> 3. When we edit the file, we start over with a new source and yaml pair.

- OK, let's move on to our second Configmap which is the index.html
- Create the index.html ConfigMap. Look closely at the --from-file portion of the command below.
```
kubectl create configmap index-html-zork  --from-file=index.html=mycode/config/index-html-zork.html
```

- Now save the generated YAML file to index-html-zork.yaml.
```
kubectl get configmaps index-html-zork -o yaml > index-html-zork.yaml
```

- List the ConfigMaps you have installed. You should see at least three.
```
kubectl get configmap
```
```
NAME                   DATA   AGE
index-html-zork        1      19m
nginx-base-conf        1      3h37m
nineteen-eighty-four   1      134m
```

- Study the `nginx-configured.yaml` Pod manifest. Note that our three ConfigMaps are included.
```yaml
---
apiVersion: v1
kind: Pod
metadata:
  name: nginx-configured
  labels:
    app: nginx-configured
spec:
  containers:
  - name: nginx
    image: nginx:1.18.0
    ports:
    - containerPort: 80
    volumeMounts:                           # these 3 files are to be injected into the container
    - name: nginx-base-config              ## links to spec.volumes.name[0] below
      mountPath: /etc/nginx/nginx.conf      # the path inside the container
      subPath: nginx.conf                   # mandatory if file exists in the container
    - name: zork                           ## links to spec.volumes.name[1] below
      mountPath: /var/www/index.html        # the path inside the container
      subPath: index.html                   # mandatory if file exists in the container
    - name: georgeorwell                   ## links to spec.volumes.name[2] below
      mountPath: /var/www/static/1984.txt   # the path inside the container
      subPath: 1984.txt                     # mandatory if file exists in the container
  volumes:
  - name: nginx-base-config                ## links to spec.containers[0]volumeMounts[0]name above
    configMap:
      name: nginx-base-conf                 # The nginx-conf.yaml configmap
  - name: zork                             ## links to spec.containers[0]volumeMounts[1]name above
    configMap:
      name: index-html-zork                 # The index.html.yaml configmap
  - name: georgeorwell                     ## links to spec.containers[0]volumeMounts[2]name above
    configMap:
      name: nineteen-eighty-four            # The nineteen-eighty-four.yaml configmap
```
![[Pasted image 20230817160227.png]]

- When a directory and config file already exists, override like this using subpath:
```yaml
containers:
- name: nginx
  volumeMounts:
    mountPath: /etc/nginx/nginx.conf
    subpath: nginx.conf
```

- If you'd like to specify a directory that does not exist as your mount point, no problem! MountPath will create it for you. `/var/www/static/` should now contain all file(s) inside your mounted volume.
```yaml
containers:
- name: nginx
  volumeMounts:
    mountPath: /var/www/static
```

# Lab 41 - Create and Consume Secrets
Secrets allow Kubernetes Administrators to encrypt and store sensitive data inside a Pod. With Kubernetes Secrets, you can store and manage sensitive information, such as passwords, OAuth tokens, and ssh keys. Storing confidential information in a Secret is safer and more flexible than putting it verbatim in a Pod definition or in a container image.

In this lab, we will:

- Encrypt sensitive data and pass it into a Secret
- Mount the Secret as a volume in a Pod

Read more about Kubernetes Secretes here: [https://kubernetes.io/docs/concepts/configuration/secret/](https://kubernetes.io/docs/concepts/configuration/secret/)

Secret Design Documentation: [https://github.com/kubernetes/design-proposals-archive/blob/main/auth/secrets.md](https://github.com/kubernetes/design-proposals-archive/blob/main/auth/secrets.md)

- MySQL uses a login/password method for authentication. Since we need to keep the password secret, this is a perfect example of how to use the Kubernetes where `Kind= Secret`. 
- Let's create the yaml to define our MySQL secret. The code speaks for itself. Note that the password is far too simple for the real world.
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
type: kubernetes.io/basic-auth
stringData:
  password: alta3
```

- apply the secret
```
kubectl apply -f ~/mycode/yaml/mysql-secret.yaml
```

- The next step is to write a pod manifest to that will use the above secret by injecting it into your pod as an environmental variable.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mysql-locked
spec:
  containers:
  - image: mysql:8-debian
    name: mysql
    env:
    - name: MYSQL_ROOT_PASSWORD
      valueFrom:
        secretKeyRef:
          name: mysql-secret
          key: password
    ports:
    - containerPort: 3306
      name: mysql
```

- In the manifest, we set an environment variable for **MYSQL_ROOT_PASSWORD**, based on the secret we made at the beginning of the lab. Now that the password is on the pod, how secure is it? Let's find out.
	- It appears the password isn't very safe at all. This is the inherenet risk with using secrets in Kubernetes. Though there are methods to further safeguard our sensitive data using secrets, out-of-the-box; kubernetes secrets aren't very secret.
```
echo $MYSQL_ROOT_PASSWORD
```